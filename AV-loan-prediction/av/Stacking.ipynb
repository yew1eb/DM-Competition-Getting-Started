{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display inline plots\n",
    "%matplotlib inline\n",
    "\n",
    "# import libraries for numerical and scientific computing\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "\n",
    "# import matplotlib for plotting\n",
    "import matplotlib as mpl\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# import pandas for data wrangling and munging\n",
    "import pandas as pd\n",
    "\n",
    "# set some options for better view\n",
    "pd.set_option('display.width', 500)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.notebook_repr_html', True)\n",
    "\n",
    "# import plotting library built on top of matplotlib\n",
    "import seaborn as sns\n",
    "\n",
    "# set some settings related to style of plots that will render\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_context(\"poster\")\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load train and test dataset\n",
    "loan_train = pd.read_csv('./data/train_u6lujuX.csv', index_col='Loan_ID')\n",
    "loan_test = pd.read_csv('./data/test_Y3wMUE5.csv', index_col='Loan_ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run scripts/data.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_cols = loan_train.columns.drop('Loan_Status')\n",
    "loan_train_features_df = loan_train[features_cols]\n",
    "target_feature = loan_train['Loan_Status']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_cols = loan_train_features_df.select_dtypes(include=['object']).columns\n",
    "non_obj_cols = loan_train_features_df.select_dtypes(exclude=['object']).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label encoded data\n",
    "train_df_enc, test_df_enc = get_label_encoded_data(loan_train_features_df, loan_test, obj_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one hot encoded\n",
    "train_df_hot, test_df_hot = get_dummy_variable_data(loan_train_features_df, loan_test, non_obj_cols, obj_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_missing_values_enc(train_df, test_df, func):\n",
    "    train_df_cpy = train_df.copy()\n",
    "    test_df_cpy = test_df.copy()\n",
    "    \n",
    "    train_df_cpy['LoanAmount'] = train_df_cpy.LoanAmount.fillna(func(train_df.LoanAmount))\n",
    "    test_df_cpy['LoanAmount'] = test_df_cpy.LoanAmount.fillna(func(test_df.LoanAmount))\n",
    "    \n",
    "    train_df_cpy['Loan_Amount_Term'] = train_df_cpy.Loan_Amount_Term.fillna(func(train_df.Loan_Amount_Term))\n",
    "    test_df_cpy['Loan_Amount_Term'] = test_df_cpy.Loan_Amount_Term.fillna(func(test_df.Loan_Amount_Term))\n",
    "    \n",
    "    train_df_cpy['Credit_History'] = train_df_cpy.Credit_History.fillna(1.0)\n",
    "    test_df_cpy['Credit_History'] = test_df_cpy.Credit_History.fillna(1.0)\n",
    "    \n",
    "    return train_df_cpy, test_df_cpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_enc_mean, test_df_enc_mean = fill_missing_values_enc(train_df_enc, test_df_enc, np.mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_hot_mean, test_df_hot_mean = fill_missing_values_enc(train_df_hot, test_df_hot, np.mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set seed\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import StratifiedKFold\n",
    "skf = StratifiedKFold(y=target_feature, n_folds=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, ExtraTreesClassifier\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (train_df_enc_mean, test_df_enc_mean, RandomForestClassifier(n_estimators=500, criterion='entropy')),\n",
    "# (train_df_hot_mean, test_df_hot_mean, RandomForestClassifier(n_estimators=500, criterion='entropy')),\n",
    "# (train_df_enc_mean, test_df_enc_mean, GradientBoostingClassifier(n_estimators=500, learning_rate=0.01)),\n",
    "# (train_df_hot_mean, test_df_hot_mean, GradientBoostingClassifier(n_estimators=500, learning_rate=0.01)),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of all the classifiers\n",
    "clfs = [(train_df_hot_mean, test_df_hot_mean, GradientBoostingClassifier(n_estimators=500, learning_rate=0.01, subsample=.8, min_samples_leaf=10)),\n",
    "        (train_df_hot_mean, test_df_hot_mean, GradientBoostingClassifier(n_estimators=500, learning_rate=0.01, subsample=.8, min_samples_leaf=10)),\n",
    "        (train_df_hot_mean, test_df_hot_mean, GradientBoostingClassifier(n_estimators=500, learning_rate=0.01, subsample=.7, min_samples_leaf=12)),\n",
    "        (train_df_hot_mean, test_df_hot_mean, GradientBoostingClassifier(n_estimators=500, learning_rate=0.01, subsample=.7, min_samples_leaf=12)),\n",
    "        (train_df_hot_mean, test_df_hot_mean, GradientBoostingClassifier(n_estimators=500, learning_rate=0.01, subsample=.6, min_samples_leaf=15)),\n",
    "        (train_df_hot_mean, test_df_hot_mean, GradientBoostingClassifier(n_estimators=500, learning_rate=0.01, subsample=.6, min_samples_leaf=15)),\n",
    "       ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "blend_train = np.zeros((train_df_enc_mean.shape[0], len(clfs)))\n",
    "blend_test = np.zeros((test_df_enc_mean.shape[0], len(clfs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results = np.zeros((len(clfs), len(skf)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_map = {'Y': 1, 'N': 0}\n",
    "target_feature_bin = np.array(target_feature.map(target_map))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training classifier [0]: GradientBoostingClassifier(init=None, learning_rate=0.01, loss='deviance',\n",
      "              max_depth=3, max_features=None, max_leaf_nodes=None,\n",
      "              min_samples_leaf=10, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "              random_state=None, subsample=0.8, verbose=0,\n",
      "              warm_start=False)\n",
      "Fold [0] Accuracy Score = 0.79365\n",
      "Fold [1] Accuracy Score = 0.82540\n",
      "Fold [2] Accuracy Score = 0.73770\n",
      "Fold [3] Accuracy Score = 0.75410\n",
      "Fold [4] Accuracy Score = 0.78689\n",
      "Fold [5] Accuracy Score = 0.78689"
     ]
    }
   ],
   "source": [
    "for j, data_clf in enumerate(clfs):\n",
    "    X_dev = data_clf[0].values\n",
    "    Y_dev = target_feature_bin\n",
    "    \n",
    "    X_test = data_clf[1].values\n",
    "    \n",
    "    clf = data_clf[2]\n",
    "    print ('\\nTraining classifier [%s]: %s' % (j, clf))\n",
    "    blend_test_j = np.zeros((X_test.shape[0], len(skf)))\n",
    "    \n",
    "    for i, (train_index, cv_index) in enumerate(skf):\n",
    "        # print ('Fold [%s]' % (i))\n",
    "\n",
    "        X_train = X_dev[train_index]\n",
    "        Y_train = Y_dev[train_index]\n",
    "        X_cv = X_dev[cv_index]\n",
    "        Y_cv = Y_dev[cv_index]\n",
    "\n",
    "        # print(\"fit\")\n",
    "        if 'fit_cv' in dir(clf):\n",
    "            clf.fit_cv(X_train, Y_train, [(X_cv, Y_cv)])\n",
    "        else:\n",
    "            clf.fit(X_train, Y_train)\n",
    "\n",
    "        one_result = clf.predict(X_cv)\n",
    "        blend_train[cv_index, j] = one_result\n",
    "        cv_score = accuracy_score(Y_cv, blend_train[cv_index, j])\n",
    "        cv_results[j, i] = cv_score\n",
    "        print ('Fold [%s] Accuracy Score = %0.5f' % (i, cv_score))\n",
    "        blend_test_j[:, i] = clf.predict(X_test)\n",
    "    blend_test[:, j] = blend_test_j.mean(1)\n",
    "    print ('Clf_%d Mean Accuracy Score = %0.5f (%0.5f)' % (j, cv_results[j,].mean(), cv_results[j,].std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV-Results 0.802923063579\n"
     ]
    }
   ],
   "source": [
    "print \"CV-Results\", cv_results.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegressionCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cs = [0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "bclf = LogisticRegressionCV(Cs)\n",
    "bclf.fit(blend_train, Y_dev)\n",
    "\n",
    "Y_test_predict = bclf.predict(blend_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run scripts/helper.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test_predict_labels = [inverse_mapping(pred) for pred in Y_test_predict]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_submissions(loan_test.index.values, Y_test_predict_labels, 'stacking_4.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}